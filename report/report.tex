\documentclass[12pt]{article}
\title{\textbf{Tupac Inventors: Investigation into 3D Modelling and Holography}}
\date{\today}
\author{Ben Sterling, Dongkyu Kim, Junbum Kim, David Kim \\ Advisor: Sam Keene \\ The Cooper Union \\ Department of Electrical Engineering}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{mathtools}
\usepackage{listings}
\usepackage{courier}
\usepackage[pdftex]{graphicx}
\usepackage{xfrac}
\renewcommand{\baselinestretch}{1.5} %for double space
% for citation
\usepackage{url}
\usepackage{breakurl}
\usepackage[breaklinks]{hyperref}

\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}
\begin{document}
\maketitle
\clearpage

\section{Introduction}
\qquad
Fast prototyping of real-world object has been addressed by many engineers and companies over the past few decades. For instance, 3D printing has especially gained much attention for its practicality. 3D printing has significantly decreased the time required to produce visible and tangible products to a few hours from weeks. On the other end of the spectrum, holography has been attracting attention due to its potentials. This technology, compared to 3D printing, can produce more interactive results at the cost of tangibility. Moreover, holography-based 3D printing is much faster than the traditional 3D printer that builds one microscopic layer at a time, hence reducing the time required to seconds instead of hours,  \cite{Shusteffeaao5496}. These characteristics make holography technology a crucial tool in 3D modeling on its own and also in the context of 3D printing.

However, the application of 3D holography still remains a mystery because of its barriers to the entry. Not only the parts required for the technology are too expensive for easy access, but the theory behind the technology requires a sophisticated understanding of physics for reliable holography projections. These traits make holography very interesting, and successful investigation of the technology will add a great value to the scientific community. In this paper, 3D modeling and holographic projections will be explained to familiarize the audience with the concept to enhance further investigations.

\par
The following sections of the paper are organized as follows. Chapter 2 describes the system pipeline that includes the sampling stage, the digital conversion stage, the transmission stage. The sampling stage scans a real-world object and stores it digitally on a computer. The digital conversion stage transforms the digitally stored data into a holographic compatible format. The transformed image is then transmitted into the holographic machine called Spatial Light Modulator (SLM). The last component, the optical holography projection stage is required to produce a relatively affordable holographic image of a real-life object. This holography section requires additional knowledge to fully understand, so in Chapter 3, details of how holography works and the details of the optical holography projection stage are illustrated. In Chapter 4, the project setup is explained including the list of materials and the physical set up. In Chapter 5, background information on stereoscopic pairs, which imbue the 3D effect is given. Then, in Chapter 6, the final conclusion of the project and the future goals are stated.

\newpage
\section{System Pipeline}

\subsection{Sampling Stage}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{sampling}
    \caption{Sampling object using Kinect}
    \label{fig:Sampling}
\end{figure}

\qquad
The first stage of the project is sampling a real-world object and storing it into a computer digitally. Since the perception of depth is a crucial part of the 3D holographic projection, it is imperative to sample both the shape and the depth of a real object. In this experiment, Xbox Kinect for Windows Development was used to sample objects. Kinect was originally developed as a module for Xbox to track human motions for entertainment purposes. It can capture an object from a single viewpoint and reconstruct 3D models based on the single viewpoint using a depth sensor and an infrared sensor. In Figure \ref{fig:Sampling}, a hardware connection layout of the sampling stage is shown.

Windows Presentation Foundation (WPF) application was built to communicate the hardware with software. The program was developed using C\# which is the natural platform for the machine. Kinect Studio Version 2.0 and Kinect Software Development Kits were installed to develop the program. Specifically, the KinectFusionExplorer module proved practical for the purpose. The module allows 3D modelling from a single photo shoot from one angle by reconstructing picture from the ordinary camera, the infrared sensor, and the depth sensor. Although the technology cannot provide a 360-degree capture of the sample, this module does reconstruct the sides of the image with only small depth errors. As the Kinect hardware needs information from all three cameras, it requires larger bandwidth compared to other commercial cameras. Hence, USB 3.0 is required to reproduce the program for the extra bandwidth. Features such as shape and depth collected from the Kinect are stored in the computer to later be transformed. More details in what information needs to be encrypted into holographic image will be discussed later. In Figure \ref{fig:kinect}, images created by the camera (left), the depth sensor (top right), and the infrared sensor (bottom right) are shown.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{kinectsample}
    \caption{Sample data obtained from Kinect}
    \label{fig:kinect}
\end{figure}

The WPF application serves two important purposes. Firstly, it provides a user-friendly interface so that the users can use the application without much difficulty. The users can select the thresholds at which they want to set their foreground and background of the sampled data. These would allow users to produce a holographic image without having to know the details of the functionality. Secondly, it allows the integration of different programming modules that is needed for the final product. Specifically, the data extracted from the Kinect need to be converted into a proper usable format, and be sent to the Spatial Light Modulator (SLM). There are existing libraries to transmit data to SLM in python. C\# WPF applications allow users to execute python script on top of the application. To summarize, the application serves as an easy way to integrate software parts while hiding unnecessary details from the end users.

\subsection{Digital Conversion Stage}

The first program that has to run on top of the WPF application transforms the image obtained from the previous sample stage to an SLM compatible format. The SLM that is available for the project is JD9554 spatial light modulator, which is part of Jasper Display's EDKv2 education kit. This modulator is a phase-only modulator, hence the program must convert images into phase masks that contain enough information to reconstruct an image. There are multiple ways of achieving this result, but one of the most efficient and popular approaches for this project is the kinoform method. The kinoform method is based on the observation that when the actual projection occurs, there are random-phase masks applied to the object pattern, making the amplitude of the actual object pattern unimportant. However, according to Poon, the kinoform method without any additional adjustment is very noisy due to its dimension reducing nature \cite{Poon14}. In order to optimize the phase-only holograms, iterative Fourier transform algorithm (IFTA) is used. This algorithm reduces the error of the reconstructed image by smoothing out the complex amplitude through iterations.

In Figure \ref{fig:RMSE}, the root mean square error (RMSE) curve for the reconstruction based on the IFTA algorithm with increasing iteration is shown. The error compares the average of the squared differences between the pixel values of the original image and the image after the reconstruction using the algorithm. There is a big drop in the error from iteration 1 to 4, and a plateau from 4 to 10, and then the error starts to decay again. Each iteration takes about 0.1 seconds, and for the real-time application, doing only 4 loops of IFTA algorithm would be the most beneficial case, as it delivers a reasonable quality in the shortest time. Fig. \ref{fig:images_recon} contains images regarding the experiment with the algorithm. ``peppers.png'' picture was used for the original image which is shown on the top left, and a corresponding phase masks for the SLM was obtained and shown on the top right. Reconstructed images after 2nd and 20th iterations are shown on the bottom left and the bottom right respectively. It is important to note that the phase mask will be the information that will be transferred to the SLM and used to steer the incoming lights to create the hologram.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{subroutine2.png}
    \caption{Root Mean Square Error (RMSE) of the Reconstructed Image to the Original Image}
    \label{fig:RMSE}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{Result.png}
    \caption{Collection of Images for the Performance Measurement}
    \label{fig:images_recon}
\end{figure}

\subsection{Digital Projection Stage}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{transmission}
    \caption{Transmitting data from Computer to SLM}
    \label{fig:transmit}
\end{figure}

In the most basic form, SLM can be considered as a monitor that displays a screen obtained from a computer. The specific SLM in use connects to the computer via an HDMI port. For the manipulation of the image shown on the SLM screen, slmPy, a python module created to dynamically control the SLM by Sebastien Popoff \cite{slmPy}, was used. The depth and the phase information of the image produced from the digital conversion stage can be sent to the SLM as numpy arrays using the slmPy module. The module has a function that retrieves the resolution of the screen, which may be critical for the successful projection of the holography. The depth and the phase information is then displayed on the reflective surface of the SLM, which simultaneously is shined by a laser that goes through a beam splitter. The laser that reflects off of the surface will contain the depth and phase information of the image, which subsequently will be projected on a 2D screen as holography. A schmatic of this process is shown in Figure \ref{fig:transmit}.

\newpage
\section{Holography Background}

In this section, fundamentals of waves and holography are presented to help the readers understand the science and engineering behind this project.

\subsection{Wave Fundamentals}

The fundamentals of Holography start from Maxwell's Equations. In the most general case, they are formulated as follows:

\begin{equation}
	\nabla \cdot \vec{D} = \rho\\
\end{equation}

\begin{equation}
	\nabla \cdot \vec{B} = 0
\end{equation}

\begin{equation}
	\nabla \times \vec{H} = \vec{J} + \frac{\partial \vec{D}}{\partial t}
\end{equation}

\begin{equation}
	\nabla \times \vec{E} = -\frac{\partial \vec{B}}{\partial t}
\end{equation}

In this project, light waves travel in the air, so there is no source charge or current. This leads to the condition, \(\rho\) = 0 and \(\vec{J}\) = \(\vec{0}\). Here are the equations with no sources:

\begin{equation}
	\nabla \cdot \vec{D} = 0
\end{equation}

\begin{equation}
	\nabla \cdot \vec{B} = 0
\end{equation}

\begin{equation}
	\nabla \times \vec{H} = \frac{\partial \vec{D}}{\partial t}
\end{equation}

\begin{equation}
	\nabla \times \vec{E} = -\frac{\partial \vec{B}}{\partial t}
\end{equation}

Lastly, here are equations that relate D to E, and B to H. The most general relationships that describes these quantities are:

\begin{equation}
	\vec{D} = \epsilon_{0}\vec{E} + \vec{P}
\end{equation}

\begin{equation}
	\vec{B} = \mu_{0}(\vec{H} + \vec{M})
\end{equation}

To simplify the problem, all the materials are assumed to be linear, homogeneous, and isotropic. Then, the last two equations can be simplified to:

\begin{equation}
	\vec{D} = \epsilon\vec{E}
\end{equation}

\begin{equation}
	\vec{B} = \mu\vec{H}
\end{equation}

where \(\epsilon\) = \(\epsilon_{r}\)\(\epsilon_{0}\) and \(\mu\) = \(\mu_{r}\)\(\mu_{0}\) are constants. The last two equations can be combined along with Maxwell's Equations to get:

\begin{equation}
	\nabla \cdot \vec{E} = 0
\end{equation}

\begin{equation}
	\nabla \cdot \vec{H} = 0
\end{equation}

\begin{equation}
	\nabla \times \vec{H} = \epsilon\frac{\partial E}{\partial t}
\end{equation}

\begin{equation}
	\nabla \times \vec{E} = -\mu\frac{\partial H}{\partial t}
\end{equation}

then the following identity from vector calculus:

\begin{equation}
	\nabla^2F = \nabla(\nabla \cdot F) - \nabla\times\nabla\times F
\end{equation}

is used to get:

\begin{equation}
	\nabla^2E - \mu\epsilon\frac{\partial^2 E}{\partial t^2} = 0
\end{equation}

\begin{equation}
	\nabla^2H - \mu\epsilon\frac{\partial^2 H}{\partial t^2} = 0
\end{equation}

The Multi-Dimensional Fourier Transform is defined as follows:

\begin{equation}
	\hat{f} (\vec{k}) = \iint \limits_{R^n}^{} f(\vec{x})e^{-j \vec{k} \cdot \vec{x}} \,d\vec{x}
\end{equation}

and a plane wave is defined as follows:

\begin{equation}
	\vec{E} = \vec{E_{0}}e^{j \omega t - j\vec{k} \cdot \vec{x}}
\end{equation}

Because E and H field are functions of x, y, z, and time, it is possible to span all E and H fields with a superposition of plane waves. This motivates the notation:

\begin{equation}
	\vec{E} = \vec{E_{0}}\psi
\end{equation}

where

\begin{equation}
	\psi = e^{j \omega t - j\vec{k} \cdot \vec{x}}
\end{equation}

Thus, in \(\psi\) notation, the wave equation turns into:

\begin{equation}
	\nabla^2\psi - \mu\epsilon\frac{\partial^2\psi}{\partial t^2} = 0
\end{equation}

\subsection{Plane and Spherical Wave Applications}

For a single frequency, signal of interest is the complex amplitude, \(\psi_{p}\) which is defined as follows:

\begin{equation}
	\psi = \psi_{p}e^{j \omega t}
\end{equation}

This can be regarded as the phasor representation of \(\psi\).

The central application of the classical theory is to develop the math behind Fresnel Diffraction. An aperture can be visualized by Figure \ref{fig:aperture}:

\begin{figure}
    \centering
    \includegraphics[width=100mm]{tupac5.png}
    \caption{Illustration of a Sample Aperture}
    \label{fig:aperture}
\end{figure}

\(k_{0}\) can be defined as the wave number in free space, such that

\begin{equation}
	\nabla^2\psi_{p} + k_{0}^2\psi_{p} = 0
\end{equation}

since

\begin{equation}
	\lambda f = c \rightarrow k_{0} = \omega/c
\end{equation}

By considering the incoming plane wave as a superposition of plane waves just like the Multi-Dimensional Fourier Transform the case, the following result can be obtained:

\begin{equation}
	\mathscr{F} \Big\{ \frac{\partial^2 \psi_{p}}{\partial x^2} \Big\} = (-jk_{x})^2\Psi_{p} = -k_{x}^2\Psi_{p}
\end{equation}

and

\begin{equation}
	\mathscr{F} \Big\{ \frac{\partial^2 \psi_{p}}{\partial y^2} \Big\} = (-jk_{y})^2\Psi_{p} = -k_{y}^2\Psi_{p}
\end{equation}

where

\begin{equation}
	\Psi_{p} = \mathscr{F} \{\psi_{p}\}
\end{equation}

Finally, if the Fourier Transform of both sides of (26) is taken to obtain:

\begin{equation}
	\frac{\partial^2\Psi_{p}}{\partial z^2} + k_{0}^{2} \bigg ( 1 - \frac{k_{x}^2}{k_{0}^2} - \frac{k_{y}^2}{k_{0}^2} \bigg ) \Psi_{p} = 0
\end{equation}

While this looks complicated, it is really only an Ordinary Differential Equation of \(\Psi_{p}\) with respect to z. Its solution is:

\begin{equation}
	\Psi_{p} = \big(\Psi_{p}\vert_{z = 0}\big) exp\Bigg(-jk_{0}z\sqrt{1 - \frac{k_{x}^2}{k_{0}^2} - \frac{k_{y}^2}{k_{0}^2}}\Bigg)
\end{equation}

If it is assumed that:

\begin{equation}
	\Psi_{p0} = \big(\Psi_{p}\vert_{z = 0}\big)
\end{equation}

Then the solution for (32) can be represented as the following transfer function:

\begin{equation}
	\mathscr{H} = \frac{\Psi_{p}}{\Psi_{p0}} = exp\Bigg(-jk_{0}z\sqrt{1 - \frac{k_{x}^2}{k_{0}^2} - \frac{k_{y}^2}{k_{0}^2}}\Bigg)
\end{equation}

\(\mathscr{H}\) is the Spatial Frequency Transfer Function of Propagation. It applies to the specific apparatus under consideration and describes the Fresnel Diffraction of the output of a plane wave hitting the aperture. \(\psi_{p0}\) is the function controlled by the shape of the aperture; if this equals \(\delta(x,y)\), for example, then the output of the aperture is purely the Spatial Frequency Transfer Function response, because this is equivalent to convolving with a delta in 2-Dimensions, returning \(\mathscr{F}^{-1} \{\mathscr{H}\} \) in the time domain.

\subsubsection{Fresnel Diffraction}

From the previous section, \(\mathscr{H}\) is obtained, but more often than not, the traveling waves make very small angles from the normal direction of the aperture. Then the Paraxial Approximation can be utilized:

\begin{equation}
	\sqrt{1 - \frac{k_{x}^2}{k_{0}^2} - \frac{k_{y}^2}{k_0^2}} \approx 1 - \frac{k_{x}^2}{2k_{0}^2} - \frac{k_{y}^2}{2k_{0}^2}
\end{equation}

Under this approximation, the Spatial Frequency Transfer Function of Propagation simplifies to:

\begin{equation}
	\mathscr{H} = exp(-jk_{0}z)exp\bigg[\frac{j(k_{x}^2 + k_{y}^2)z}{2k_{0}}\bigg]
\end{equation}

In this specific example, the Two Dimensional Fourier Transform (z remains constant):

\begin{equation}
	\Psi_{p}(k_{x},k_{y},z) = \iint \limits_{R^2}^{} \psi_{p}(x,y,z)e^{-jk_{x}x - jk_{y}} \,dx\,dy
\end{equation}

can be used to get the Spatial Impulse Response, h:

\begin{equation}
	h(x,y,z) = \mathscr{F}^{-1}\{\mathscr{H}\} = \frac{jk_{0}}{2\pi z} exp(-jk_{0}z)exp\bigg[\frac{-jk_{0}(x^2 + y^2)}{2z}\bigg]
\end{equation}

\subsection{Holography Fundamentals}

The simplest holography setup, and a good starting point to understanding the subject, is this collection off Fresnel plates in Figure \ref{fig:Fresnel_Plates}.

\begin{figure}
    \centering
	\includegraphics[width=100mm]{tupac7.png}
    \caption{The Collection of Fresnel Plates}
    \label{fig:Fresnel_Plates}
\end{figure}

First, a collimated laser is used so that the direction of propagation of each wave is parallel. The first beam splitter (BS1) divides the laser in two paths of equal power. One path will be used as a reference and the other path will contain the object information. The two paths recombine at the second beam splitter (BS2). If the object wave is denoted as \(\psi_{0}\) and the reference wave is \(\psi_{r}\), and if the aperture is assumed to be a pinhole, and using \(\delta(x,y)\) as the input function that references the Spatial Frequency Transfer Function:

\begin{equation}
	\begin{multlined}
		\psi_{0}(x,y,z_{0}) = \delta(x,y) * h(x,y,z_{0}) = h(x,y,z_{0})
		\\= exp(-jk_{0}z_{0})\frac{jk_{0}}{2\pi z_{0}}exp\bigg[\frac{-jk_{0}(x^2 + y^2)^2}{2z_{0}}\bigg]
	\end{multlined}
\end{equation}

If \(\psi_{r}\) is just a plane wave propagating in the \(z_{0}\) direction:

\begin{equation}
	\psi_{r} = a\,exp(-jk_{0}z_{0})
\end{equation}

It is important to note that the light intensity is proportional to square of the complex amplitude, I(x,y) \(\propto\) \(|\psi_{p}(x,y)|^2\).
Thus we define transmittance, t(x,y) as:

\begin{equation}
	t(x,y) = |\psi_{p}(x,y)|^2
\end{equation}

For this project:

\begin{equation}
	\begin{multlined}
	t(x,y) = |\psi_{o}(x,y) + \psi_{r}(x,y)|^2
	=(\psi_{o} + \psi_{r})(\psi_{o} + \psi_{r})^*
	\\= a^2 + (\frac{k_{0}^2}{2\pi z_{0}})^2 - \frac{-jk_{0}a}{2\pi z_{0}}
	exp\bigg[ \frac{jk_{0}}{2z_{0}}(x^2 + y^2) \bigg] +
	\\\frac{-jk_{0}a}{2\pi z_{0}}
	\exp\bigg[\frac{-jk_{0}}{2z_{0}}(x^2 + y^2) \bigg]
	\end{multlined}
\end{equation}

The sine function inside the last line can be recognized as:

\begin{equation}
	t(x,y) = a^2 + \big(\frac{k_{0}}{2\pi z_{0}}\big)^2 +
	\frac{ak_{0}}{\pi z_{0}}sin\bigg[\frac{k_{0}}{2z_{0}}(x^2 + y^2)\bigg]
\end{equation}

Hence the diffraction pattern of this aperture will look like as in Figure \ref{fig:diff_pattern}.

\begin{figure}
    \centering
    \includegraphics[width=50mm]{tupac8.png}
    \caption{Sample Diffraction pattern}
    \label{fig:diff_pattern}
\end{figure}

By inspection, the output of the machine obeys a sinusoidal pattern, with some DC value in towards the center (x = 0 and y = 0), and the frequency
of the sinusoid increases parabolically moving radially outward.
Also, for any tangent vector \(v_{p}\), the spatial frequency is defined as the directional derivative of the angle:

\begin{equation}
	v_{p}\bigg[ \frac{k_{0}(x^2 + y^2)}{2z_{0}} \bigg] = \frac{k_{0}}{z_{0}}(v_{1}p_{1} + v_{2}p_{2}), \forall v_{p} \in T_{p} \mathbb{R}^2
\end{equation}

This result is more significant in differential form:

\begin{equation}
	d \bigg( \frac{k_{0}(x^2 + y^2)}{2z_{0}} \bigg) = \frac{k_{0}}{z_{0}}(xdx + ydy)
\end{equation}

The frequency increases linearly in any arbitrary direction.
It is important to note that an observer at a distance will see the following
\(\psi_{rec}\) instead because the observer is at a distance, z, away from the
recording medium:

\begin{equation}
	\psi_{p} = \psi_{rec}t(x,y)*h(x,y,z)
\end{equation}

where \(\psi_{rec}\) is the field on the projecting surface.

\subsubsection{3D Holographic Imaging}

In this next section, the effects of different co-planar displacements (x and y) and different distances from the medium (z) are identified. The problem can be visualized using the diagrams in Figure \ref{fig:diagram1}, and Figure \ref{fig:diagram2}.

\begin{figure}
    \centering
    \includegraphics[width=100mm]{tupac11.png}
    \caption{Diagram 1 for Illustration of the Problem}
    \label{fig:diagram1}
\end{figure}


\begin{figure}
    \centering
    \includegraphics[width=100mm]{tupac12.png}
    \caption{Diagram 2 for Illustration of the Problem}
    \label{fig:diagram2}
\end{figure}

The first graph in Figure \ref{fig:diagram1} displays two source points with a reference wave R, and the second in Figure \ref{fig:diagram2} displays the reconstructed point r (the location a viewer SEE'S the object).

The following identity under convolution helps to simplify the upcoming calculations.

\begin{equation}
	\delta(x - \alpha,y - \beta)*h(x,y,z) = \delta(x,y)*h(x - \alpha,y - \beta,z)
\end{equation}

The physical significance of this identity is that being off-center from the pinhole aperture is equivalent to translating the center Spatial Impulse Response. Thus, the three relevant complex fields can be identified as follows:

\begin{equation}
	\psi_{p1} = \delta(x - \frac{h}{2},y)*h(x,y,R) = h(x - \frac{h}{2},y,R)
\end{equation}

\begin{equation}
	\psi_{p2} = \delta(x + \frac{h}{2},y)*h(x,y,R + d) =
	h(x - \frac{h}{2},y,R + d)
\end{equation}

\begin{equation}
	\psi_{pR} = \delta(x + a,y)*h(x,y,l_{1}) = h(x + a,y,l_{1})
\end{equation}

Now, the intensity can be found as follows by definition:

\begin{equation}
	\begin{multlined}
	t(x,y) = |\psi_{p1} + \psi_{p2} + \psi_{pR}|^2
	\\ (\psi_{p1} + \psi_{p2} + \psi_{pR})(\psi_{p1} + \psi_{p2} + \psi_{pR})^*
	\end{multlined}
\end{equation}

Each \(\psi_{pi}\psi_{pi}^*\) for \(i \in \mathbb{Z}^+\) is not very interesting, because the wave parts cancel and they are just zeroth order waves.
Also, note \(\psi_{pi}\psi_{pj}^* = (\psi_{pj}\psi_{pi}^*)^* \), so only three transmittances are needed to determine the intensity

If only one transmittance is taken:

\begin{equation}
	t_{rel1}(x,y) = \psi_{p1}^*\psi_{pR}(x,y) = exp(\frac{jk_{0}}{2R}[(x - \frac{h}{2})^2 + y^2])exp(\frac{-jk_{0}}{2R}[(x + a)^2 + y^2])
\end{equation}

and then solved for the reflected \(\psi\), the following equation is obtained:

\begin{equation}
	\psi_{pr}(x,y)t_{rel1}(x,y)*h(x,y,z)
\end{equation}

where:
\begin{equation}
	\psi_{pr} = \delta(x - b,y)*h(x,y,l_{2}) = h(x - b,y,l_{2})
\end{equation}

This must be true because independent of the points 1 and 2, the field is being
affected by a plane wave coming from the reconstruction point. Thus the approximation of the reflected wave is given by:

\begin{equation}
	\begin{multlined}
	\psi_{ref} \propto exp\bigg(\frac{-jk_{0}}{2l_{2}}[(x - b)^2 + y^2]\bigg)
	exp\bigg(\frac{-jk_{0}}{2R}[(x - \frac{h}{2})^2 + y^2]\bigg)
	\\exp\bigg(\frac{-jk_{0}}{2l_{1}}[(x + a)^2 + y^2]\bigg)
	*\frac{jk_{0}}{2\pi z}exp\bigg(\frac{-jk_{0}}{2z}[x^2 + y^2]\bigg)
	\end{multlined}
\end{equation}

2D convolution is defined as follows:

\begin{equation}
	\big(f_{1}*f_{2}\big)(x,y) = \iint \limits_{R^2}^{} f_{1}(x',y')f_{2}(x - x',y - y') \,dx'\,dy'
\end{equation}

The coefficients in front of \(x'^2\) and \(y'^2\) must equal zero because the convolution in (55) must evaluate to a \(\delta\) function.
As if it did not evaluate to a \(\delta\), this would imply the field has multiple non-zero space values for a single image point. Single points do not spread into clouds, as this would violate empirical observations. Thus by inspection, the following equation can be derived:

\begin{equation}
	\frac{1}{R} - \frac{1}{l_{1}} - \frac{1}{l_{2}} - \frac{1}{z_{r1}} = 0
\end{equation}

Through some algebra following equation can be obtained:

\begin{equation}
	\psi_{ref} \propto \delta \bigg[ x + z_{r1}\bigg(
	\frac{b}{l_{2}} - \frac{h}{2R} - \frac{a}{l_{1}}\bigg),y\bigg]
\end{equation}

Similarly for the second point:

\begin{equation}
	\frac{1}{R + d} - \frac{1}{l_{1}} - \frac{1}{l_{2}} - \frac{1}{z_{r2}} = 0
\end{equation}

\begin{equation}
        \psi_{ref} \propto \delta \bigg[ x + z_{r2}\bigg(
        \frac{b}{l_{2}} - \frac{h}{2(R + d)} - \frac{a}{l_{1}}\bigg),y\bigg]
\end{equation}

These equations are the starting point to understanding magnification and translation distortion of images.

\subsubsection{Holographic Magnification}

In this context, magnification is defined as:

\begin{equation}
	M_{Long}^r = \frac{z_{r2} - z_{r1}}{d}
\end{equation}

This is the ratio of the hologram depth over the real depth between these two points.

From equation (57) and (59) (Assuming: R \(\gg\) d), substitution can be made to yield the following equation.

\begin{equation}
	M_{Long}^r = \bigg(\frac{l_{1}l_{2}}{l_{1}l_{2} - Rl_{1} - Rl_{2}}\bigg)^2
\end{equation}

The lateral magnification is defined as the difference in x virtual positions over the real x distance (h). Using equations (58) and (60), the following equation can be obtained assuming \(R \gg d\):

\begin{equation}
	\begin{multlined}
		M_{Lat}^r = \frac{z_{r2}\bigg( \frac{b}{l_{2}} + \frac{h}{2(R + d)} - \frac{a}{l_{1}}\bigg) - z_{r1}\bigg(\frac{b}{l_{2}} - \frac{h}{2R} - \frac{a}{l_{1}} \bigg)}{h}
		\\\approx \frac{(z_{r2} - z_{r1})\bigg(\frac{b}{l_{2}} -\frac{a}{l_{1}} \bigg) + (z_{r2} + z_{r1})\frac{h}{2R}}{h}
	\end{multlined}
\end{equation}

If the points are aligned in a special way such that:

\begin{equation}
	\frac{b}{l_{2}} - \frac{a}{l_{1}} = 0
\end{equation}

the following simplification can be made:

\begin{equation}
	M_{Long}^r = (M_{Lat}^r)^2
\end{equation}

\subsubsection{Holographic Translation}

The equation for lateral magnification gives the distortion between two holographic points if (64) is not met:

\begin{equation}
	\Delta x = x_{1} - x_{2} = (z_{r2} - z_{r1})\bigg(\frac{b}{l_{2}} - \frac{a}{l_{1}}\bigg)
\end{equation}

In Figure \ref{fig:deltax}, the diagram shows how an artificial \(\Delta x\) comes about from erroneous orientation.

\begin{figure}
    \centering
    \includegraphics[width=100mm]{tupac13.png}
    \caption{Source of \(\Delta x\)}
    \label{fig:deltax}
\end{figure}

\subsubsection{Off-Axis Holography}

The standard holography setup explained so far is called on-axis holography. The only problem with this approach is that twin images are obtained when the full equation for transmittance is used due to the conjugation terms.

\begin{equation}
	t(x,y) = |\psi_{r} + \psi_{o}|^2 = |\psi_{r}|^2 + |\psi_{o}|^2
	 + \psi_{r}^*\psi_{o} + \psi_{r}\psi_{o}^*
\end{equation}

Off-Axis holography takes care of this problem by introducing the reference
light at an angle \(\theta\) as shown in Figure \ref{fig:off-axis}.

\begin{figure}
    \centering
    \includegraphics[width=100mm]{tupac9.png}
    \caption{Off-Axis Holography}
    \label{fig:off-axis}
\end{figure}

The logic of equation (67) can be restated as follows (the extra phase factor comes out from the extra distance the reference wave needs to travel)

\begin{equation}
	\begin{multlined}
	t(x,y) = |\psi_{r}e^{jk_{0}sin\theta x} + \psi_{o}|^2 = |\psi_{r}|^2 + |\psi_{o}|^2
         + \psi_{r}^*\psi_{o}e^{-jk_{0}sin(\theta) x} + \psi_{r}\psi_{o}^*e^{jk_{0}sin(\theta)x}
	\\=|\psi_{r}|^2 + |\psi_{o}|^2 + 2|\psi_{0}^*\psi_{r}|cos(2\pi f_{x}x + \phi (x,y))
	\end{multlined}
\end{equation}

The phase getting scaled by \(xsin(\theta)\) makes sense because at \(\theta = \pi/2\), the extra distance turns into just x, and at \(\theta = 0\)
the reference wave is already in phase with the object wave, so no adjustment would be necessary. Just like the earlier section, the cosine identity in the top of the last equation (the \(\phi\) can be recognized as any extra phase that came from the \(\psi_{o}\) \(\psi_{r}\) pair not counting the angle \(\theta\)), specifically, \(f_{x} = \frac{sin(\theta)}{\lambda}\).

Finally, the reconstruction light can be factored in. If it has the same magnitude and direction as the reference light, the reconstruction light can be represented with the following wave equation, which later gets convolved with h(x,y,z) to render the real image:

\begin{equation}
	\begin{multlined}
	\psi = \psi_{r}e^{jk_{0}sin(\theta)x}t(x,y)
	\\=|\psi_{r}|^2\psi_{r}e^{jk_{0}sin(\theta)x} + |\psi_{0}|^2\psi_{r}e^{jk_{0}sin(\theta)x}
	\\+ \psi_{o}|\psi_{r}|^2 + \psi_{o}^*\psi_{r}^2e^{2jk_{0}sin(\theta)x}
	\end{multlined}
\end{equation}

Upon closer examination, \(k_{0}sin(\theta)\) can be regarded as the carrier frequency (in radians). Since \(\psi_{r}\) is a reference light, it is entirely DC, so the first term in (69) is \(\Psi_{1}\), the carrier.
The second term in (69) is \(\Psi_{2}\) because the phasor convolves the magnitude-squared of the object wave out to the carrier frequency.
The third (and most important) term, \(\Psi_{3}\) is the only one that is not modulated by the carrier (it gets cancels out by the algebra).
This is the only term that is visible to the human eye.

\begin{figure}
    \centering
    \includegraphics[width=100mm]{tupac14.png}
    \caption{Illustration of Aliasing}
    \label{fig:aliase}
\end{figure}

By inspection from the Figure \ref{fig:aliase}, the minimal angle \(\theta\) that is needed to prevent aliasing can be given by:

\begin{equation}
	k_{0}sin(\theta) \geq \frac{3B}{2}
\end{equation}

\begin{figure}
    \centering
    \includegraphics[width=100mm]{tupac10.png}
    \caption{Illustration of Aliasing}
    \label{fig:project_setup}
\end{figure}

\newpage
\section{Project Setup}

In Figure \ref{fig:project_setup}, the diagram illustrating the project is shown. The software component is on the top as described before. The system starts on the bottom left corner with a coherent laser source. The laser should be coherent to reduce random phase artifacts which degrade the quality of the final hologram. Then the pinhole apparatus can be used to filter out the higher order noise artifacts that might be introduced by the laser. The pinhole apparatus centers the laser by converting the incoming plane waves of the laser into a spherical wave, which turns into a plane wave again after applying the paraxial approximation. By experiment, the effect of the pinhole apparatus was not impactful to the final projection, hence this pinhole portion can be skipped. However, in place of the pinhole apparatus, collimating lense can be placed to spread the narrow laser beam so that the beam can be centered and widened enough to cover the whole SLM. After shaping the beam to an appropriate size, a polarizer is placed so that the light going into the SLM has the anticipated linear polarization.

A beam splitter is placed in between the polarizer and the spatial light modulator (SLM) to send half of the incoming beam to the SLM, and the other half to the screen. The SLM is electronically steered by the incoming video signal. The SLM has 8 bit precision in the phase of the wave that it reflects. An important note is that the wave reflected off the SLM needs to occupy the same physical space as the incoming wave. Finally, the reflected wave goes into the beam splitter and sums with the incident light as both waves travel to the recording medium.

\subsection{List of Materials}
The following components are used to build the system: a JD9554 Spatial Light Modulator, a P20S 20 micro-meter pinhole from Thorlabs, a BS013 Cube Beam Splitter, AL2520-A collimated lenses, C560TME-B Aspheric Lens, an LPVISE200-A Polarizer, and a high powered laser.

\subsection{Physical Setup}
At the very end of the first semester, all the parts needed to finish the SLM setup arrived. The problem was the precision at which the parts were supposed to be placed with. In addition, the parts that arrived did not fit well with the holders that were available. As a result of the poor precision in the placement of the components, the initial output from the initial set up was too dim to be seen. These problems led to test whether the laser was powerful enough to generate the hologram. However, after consultation with Professors including Professor Wolf as he has the most holography experience in the school, and researching papers, the power of the laser that was available was confirmed to be adequate.

[TODO: David, add a section on the interviews with professor wolf. please refrain from using personal voice (I,we, and so on as Keene likes it this way)]

In order to combat the precision issues, although it is not the ideal choice, holder parts were designed and 3D printed. The main purpose of the holder parts was to raise the components such as lenses and polarizers off the optical board by a precise height. To make the holder parts general purpose, three piece system was designed. The three part system consists of a base, a hexagonal shaft, and an insert piece that can be hand-tightened by a screw. The illustration of the system is shown in Figure \ref{fig:holder}.

\begin{figure}
    \centering
    \includegraphics[width=100mm]{holder.png}
    \caption{The Modelling of the Holder}
    \label{fig:holder}
\end{figure}

At first, 6 of this system were to be printed to account for the laser, the collimating lense, the pinhole, and polarizers. However, during the experiment while waiting for the 3D printer, it was found out that the pinhole was not necessary for a good result. Instead of a pinhole with a collimating lense, the collimating lense was used alone to produce a much wider beam of light. At the end of the experiment, only one of the holder was required for the physical set up. The holder was adjusted precisely such that all the components were aligned well to get straight paths between each other. The final setup for the system is shown in Figure \ref{fig:setup_picture}.

\begin{figure}
    \centering
    \includegraphics[width=100mm]{setup_picture.jpg}
    \caption{Physical Setup}
    \label{fig:setup_picture}
\end{figure}

After all the precise adjustment, when the laser was directed onto the SLM, an interesting pattern emerged. The pattern is shown in Figure \ref{fig:simple_pattern}. This pattern switched from diagonal lines to vertical lines when the SLM was on without any video input. As soon as the HDMI port was connected from a computer to the SLM, very noisy images that were sent to the display were projected. In Figure \ref{fig:Ben}, an example of the noisy displays is shown.

\begin{figure}
    \centering
    \includegraphics[width=100mm]{initHologram.png}
    \caption{Initial SLM Hologram}
    \label{fig:simple_pattern}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=100mm]{noisy_hologram.jpg}
    \caption{Noisy SLM Hologram}
    \label{fig:Ben}
\end{figure}

The final observation is that the polarizer makes a reduction in noise, but it is not one of the essential pieces for producing a projection. In addition, the laser that was used is already linearly polarized as rotating the polarizer sometimes completely blocks the laser's light when the incident angle is exactly 90 degrees.

\subsection{Investigation into Projecting 3D Models}
The only part of the project remaining is projecting 3D models in the real world. There are several researches done already that attempted to solve this problem. Zaperty and her colleagues successfully demonstrated the 3D holography using multiple SLMs in \cite{Zaperty:17}. However, this method requires multiple SLMs, and as only one SLM is available, a method that involves only one SLM needs to be found. In 2017, Lin and Kim demonstrated a way to display 3D models with a single SLM in \cite{lin2017single}. this method requires 3 different lasers, and 3 highly optimized filters to imbue certain optical characteristics to the beams such that beams can be adjusted by the single SLM differently. The kinds of lasers and filters that were used were too expensive to obtain. Two methods were proposed to solve the single SLM 3D effect problem. The first method was to use a thick medium to project onto, and anoother method was to use stereoscopic pairs to imbue the 3D effect.

The idea of the thick medium was to project the laser beams through the medium at different angles at the same time such that the beams will form a 3-D model of an object that floats in the medium. There have been various attempts in implementing a hologram using this technique, such as \cite{ochiai2015fairy}, and \cite{sano2017holography}. The work in \cite{ochiai2015fairy} utilizes focused femtosecond plasma lasers to fix voxels into any arbitrary space in the air, and crystal SLM to generate images desired. This system was able to generate small volumetric displays, when viewed from different angles have different scenes as the hologram occupies actual space. Unfortunately, this technique could not be incorporated to the project as femtosecond plasma lasers were required to create the holographic voxels in the air, as well as Galvano scanners to scan and steer the laser beams accurately. These devices are way beyond the budget as well: the cheapest femtosecond laser available online was 4500 USD \cite{Femto}, and Galvano scanner was about 300 USD \cite{Galvano}. However, this work indicated that it was possible to embed the hologram into a medium, although to do it in the air, more expensive devices were required. Unfortunately, all the other possible methods of creating volumetric holograms require either multiple projectors or a moving screen that rotates around a single projector \cite{sano2017holography}. As the project only has 1 SLM available, creating a true 3-D object using a single SLM was not possible.

Instead of using a thick medium, the project was decided to utilize a cross-eyed hologram; this works by displaying the right and left eyed images in front of the opposite eye so that the viewer crosses their eyes and sees a 3D image (by illusion).

\newpage
\section{Stereoscopic Pair Generation}

At this stage, the WPF application was developed to obtain a color/depth map and immediately send it to the SLM. However, the system still needed to convert color/depth information to right and left eyed views (the stereoscopic pair). There was no library to do this conversion as most provided libraries, in particular OpenCV, solved the opposite reverse problem of converting a stereoscopic pair to a color/depth map. Upon further investigation, it was determined that the problem could be solved with a simple geometry. Hence, the following solution was proposed.

\begin{figure}
    \centering
    \includegraphics[width=100mm]{eye_disp_pic.png}
    \caption{Eye Displacement Illustration}
    \label{fig:eyedisp}
\end{figure}

To create the image pair, information on how far each eye is from the center was needed to dilate pixels for the pairs accordingly. To get the eye distance, a certain focal distance (f), an eye-angle (\(\theta\)), and a pixel density (D) were assumed. The pairs are not highly sensitive to these parameters because the viewer can adjust depth as needed with the use of their finger. The values chosen were f = 2, \(\theta\) = \sfrac{\(\pi\)}{6}, and D = 75. Using these parameters, the problem is to solve for x in Figure \ref{fig:eyedisp}. Using basic trigonometry and scaling by the pixel density, the solution for x is: \[x = Df\tan(\theta)\]

The next step is to dilate each pixel depending on its depth given by the depth map and the distance from the eye:

\begin{figure}
    \centering
    \includegraphics[width=100mm]{dilation_pic.png}
    \caption{Pixel Dilation Illustration}
    \label{fig:pixeldi}
\end{figure}

Using the notation in Figure \ref{fig:pixeldi}, because the real and virtual distances form similar triangles, the equation \(r_{1}\) = \(r_{0}\)\sfrac{\(d_{1}\)}{\(d_{0}\)} is true. Note that \(d_{0}\) is not very important because it is constant. Then the following pattern as a matrix representing all the \(r_{0}\) values is constructed. The constructed values are represented visually in Figure \ref{fig:eyedistance}.

\begin{figure}
    \centering
    \includegraphics[width=100mm]{eye_distances.png}
    \caption{Eye Distances}
    \label{fig:eyedistance}
\end{figure}

It is noted that this is just a linear decay away from the eye.
The virtual distances of every pixel in an image is obtained by element-wise multiplying the image by the depth map. Finally, two "larger" matrices of all zeros are created and looped through the 2D image pixel by pixel.
Then each pixel value that is looped through at the correct position in the "larger" left and right matrices is filled according to the left and right eyed depths.

The only problem is that this mapping is not mathematically surjective, or onto. This results in dark line patterns that run down the image. To fix this dark line pattern problem, some image resolution was sacrificed. For a 2D signal, a 2D Gaussian distribution acts as a low-pass filter under 2D convolution (equation 56). To remove the dark lines, the noisy image was convolved with a Gaussian of \(\sigma\) = 2 to arrive at our final stereoscopic pairs.

The image and depth map in Figure \ref{fig:imadep} turns into the stereoscopic pair in Figure \ref{fig:stereosco} using this algorithm.

\begin{figure}
    \centering
    \includegraphics[width=100mm]{image_depth_pair.png}
    \caption{Image and Depth Map}
    \label{fig:imadep}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=100mm]{stereoscopic_pair.png}
    \caption{Stereoscopic Pair}
    \label{fig:stereosco}
\end{figure}

If one zooms into the above image, and follows the instructions detailed on this page: https://www.kula3d.com/how-to-use-the-cross-eyed-method, one should be able to view a 3D cube. It should be noted that although the link does not use a finger to focus on, but it is recommended to use a finger to adjust the focal-depth.

Finally, a goggle was used to test the system. The goggle was captured using the Kinect and shown in Figure \ref{fig:goggle}. The algorithm generated the stereoscopic pair as shown in Figure \ref{fig:goggle_stereo}. Then the pairs were projected using the holography system, and the result is shown in Figure \ref{fig:goggle_holo}.

\begin{figure}
    \centering
    \includegraphics[width=100mm]{goggles.png}
    \caption{A Goggle Captured Using the Kinect}
    \label{fig:goggle}
\end{figure}


\begin{figure}
    \centering
    \includegraphics[width=100mm]{goggle_stereoscopic.png}
    \caption{A Goggle Converted into a Stereoscopic pair}
    \label{fig:goggle_stereo}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=100mm]{final_hologram.jpg}
    \caption{A Goggle Hologram}
    \label{fig:goggle_holo}
\end{figure}

Once again, the focusing technique can be used to visualize a 3D pair of the goggles. Ben and Ostap in particular noticed that the mind naturally cleans up some of the noise artifacts when viewed in 3D (information loss in one image is alleviated by the other image possessing it).

\newpage
\section{Conclusion and Future Goals}



% The progress of the project so far was greatly hindered by materials that we need not arriving due to the Canada Post strike. However, we have started setting up the system at the lab, and we feel confident that the hologram system would work with our knowledge. On the software side of the project, the program that converts images into inputs appropriate for the spatial light modulator (SLM) is implemented in two different algorithms. In addition, the Windows Presentation Foundation application that guides the transportation of the Microsoft Kinect images or videos into the SLM is implemented and waiting for testing.

% It has been tested that the digital projection stage of the SLM assisted by slmPy module works flawlessly on a computer monitor. The desired image in the form of numpy array is automatically resized to fit the entire screen, and both still image and animation are displayed without any issue. However, additional testing on the SLM is yet to be done as the setup was not completed for projection.

% For the upcoming semester, as all the materials have finally arrived, we will be building the holography system, and starting the necessary tests to pick the optimal algorithms for image conversion, resolutions, and sample methods. We hope to be done with the building of the system and getting a complete hologram image by late February so that we can concentrate on making the holography to look more 3D like, and presented in real-time. Currently, another missing piece of the system is the program that encodes the depth information appropriately into the 2D images. Our system inherently deals with 2D images, and the only way to encode the depth information to imbue 3D-like characteristics is through simultaneous projection of phase mask and the depth information to the SLM. It is currently unknown if naively projecting them at the same time will work or additional measures need to be taken. Moreover, it is also important to figure out if we have successfully encoded the depth information without seeing the desired holography, because encoding the depth information is necessary but may not be sufficient for our final goal. These will be the top priorities to be addressed in the upcoming semester.

% While we are currently utilizing the IFTA algorithm, it is more computationally intensive than the other algorithm Poon proposes in his book. The other algorithm accounts for the Spatial Distortion that occurs from Fresnel Diffraction and thus premultiplies by the transfer function's inverse to cancel the aperture effects. We will try and get a working prototype with the IFTA algorithm first, but we can speed up computations with this other algorithm if it needed.

% For the projection stage, as there is an apparent difference between the SLM reflective surface and a computer monitor, we hope to thoroughly test it the upcoming semester. While the automatically scaled image to fit the computer screen showed no issue, it should also be tested whether such adjustments potentially disturb the quality of holography. After confirmation of reliable projection, we hope to figure out how manipulating certain settings, e.g. the frequency and intensity of the laser beam, refresh rate of the screen, would incur qualitative changes to the projection.
\newpage

\bibliographystyle{unsrt}
\bibliography{ref}

\end{document}
